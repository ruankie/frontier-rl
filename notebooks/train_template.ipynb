{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Descriptors cannot not be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/app/src/models/frontier.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#import matplotlib.pyplot as plt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m#from tensorflow.keras.models import Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[0;31m#, Input, Dropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunction_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrewriter_config_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/core/framework/function_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mattr_value_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_attr__value__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnode_def_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_node__def__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mop_def_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_op__def__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/core/framework/attr_value_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_tensor__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_shape_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_types__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/core/framework/tensor_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresource_handle_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_resource__handle__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_shape_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_types__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/core/framework/resource_handle_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_shape_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_types__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/core/framework/tensor_shape_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m       \u001b[0mmessage_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menum_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontaining_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0mis_extension\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension_scope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m       serialized_options=None, file=DESCRIPTOR),\n\u001b[0m\u001b[1;32m     43\u001b[0m     _descriptor.FieldDescriptor(\n\u001b[1;32m     44\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tensorflow.TensorShapeProto.Dim.name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/google/protobuf/descriptor.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, name, full_name, index, number, type, cpp_type, label, default_value, message_type, enum_type, containing_type, is_extension, extension_scope, options, serialized_options, has_default_value, containing_oneof, json_name, file, create_key)\u001b[0m\n\u001b[1;32m    558\u001b[0m                 \u001b[0mhas_default_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontaining_oneof\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m                 file=None, create_key=None):  # pylint: disable=redefined-builtin\n\u001b[0;32m--> 560\u001b[0;31m       \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_CheckCalledFromGeneratedFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mis_extension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFindExtensionByName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Descriptors cannot not be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os\n",
    "from src.models.frontier import MultiStockEnv, Agent, play_one_episode, maybe_make_dir\n",
    "from src.config import market_tickers\n",
    "from src.config.model_config import model_parameters\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RL_CNN': {'use_forecasts': False,\n",
       "  'nb_forecasts': None,\n",
       "  'forecast_type': 'strong',\n",
       "  'use_cnn_state': True},\n",
       " 'RL_str_fcast': {'use_forecasts': True,\n",
       "  'nb_forecasts': 2,\n",
       "  'forecast_type': 'strong',\n",
       "  'use_cnn_state': False},\n",
       " 'RL_all_inp': {'use_forecasts': True,\n",
       "  'nb_forecasts': 2,\n",
       "  'forecast_type': 'strong',\n",
       "  'use_cnn_state': True}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.config.model_config import model_parameters\n",
    "model_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# papermill parameters\n",
    "SEED_LIST = [\n",
    "             0,\n",
    "             #1111,\n",
    "             #2222, \n",
    "             #3333, \n",
    "             #4444, \n",
    "             #5555,\n",
    "             #6666,\n",
    "             #7777,\n",
    "             #8888,\n",
    "             #9999\n",
    "            ]\n",
    "\n",
    "#TICKERS = market_tickers.DOW_30_TICKER\n",
    "TICKERS = ['AAPL', 'AMD', 'CSCO', 'F', 'INTC']\n",
    "MARKET_NAME = 'TEST_5'\n",
    "MODEL_BASE_NAME = 'RL_CNN' # use either | 'RL_CNN' | 'RL_str_fcast' | 'RL_all_inp' |\n",
    "FROM = '2017-01-03' # start of training set\n",
    "UNTIL = '2019-01-01' # end of training set\n",
    "NB_EPISODES = 200 # number of episodes to train for\n",
    "SAVE_EVERY = 200 # (used 100 when not from tretrained) save model weights every time this amount of episodes pass\n",
    "\n",
    "# investor preferences\n",
    "GAMMA_TRADES = [0.1, 1, 10, 100]\n",
    "GAMMA_RISKS = [0.1, 1, 10, 100, 1000]\n",
    "GAMMA_HOLDS = [0.1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of trios:  40\n"
     ]
    }
   ],
   "source": [
    "#------ small test-sweep ------#\n",
    "# GAMMA_TRADES = [0.1, 1, 10, 100]\n",
    "# GAMMA_RISKS = [0.1, 1, 10, 100, 1000]\n",
    "# GAMMA_HOLDS = [0.1, 1]\n",
    "#------ extended-boyd-sweep ------#\n",
    "# GAMMA_TRADES =  [0.1, 0.5, 1, 2, 3, 4, 5, 5.5, 6, 6.5, 7, 7.5, 8, 9, 10, 11, 12, 15, 20, 30, 45, 60, 100, 200]\n",
    "# GAMMA_RISKS = [0.1, 0.178, 0.316, 0.562, 1, 2, 3, 6, 10, 18, 32, 56, 100, 178, 316, 562, 1000, 2000, 5000, 10000, 20000]\n",
    "#---------------------------------#\n",
    "\n",
    "GAMMA_TRIOS = []\n",
    "for tr in GAMMA_TRADES:\n",
    "    for ri in GAMMA_RISKS:\n",
    "        for hd in GAMMA_HOLDS:\n",
    "            GAMMA_TRIOS.append((tr, ri, hd))\n",
    "        \n",
    "#format: (gamma_trade, gamma_risk, gamma_hold)\n",
    "print('number of trios: ', len(GAMMA_TRIOS))\n",
    "#GAMMA_TRIOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other constants and parameters\n",
    "TICKERS.sort()\n",
    "FILE_PERIOD = '1d' # weekly='5d', daily='1d'\n",
    "DAYS_IN_EPISODE = 30 # 365 for one-year long episodes (conditions checked at end of episode)\n",
    "EPISODE_DRAW_DISTRIBUTION = 'uniform' # 'uniform' or 'geometric'. select starting point of eposide according to this distribution when generated\n",
    "HALF_SPREAD = 0.0005/2.0 # 'a' in transaction cost function\n",
    "NONLIN_COEFF = 1.0 # 'b' transaction cost function\n",
    "POWER = 1.5 # power for change in poertfolio vector used in transaction cost\n",
    "#GAMMA_RISK, GAMMA_TRADE, GAMMA_HOLD = 18, 6.5, 0.0 # relative importance of risk, trading cost, and holding cost\n",
    "INIT_PORTFOLIO = 100000000.0 # initial portfolio value\n",
    "#model_name = f'REINFORCE_CNN' #_seeded_{UNTIL} # give model a name to distinguish saved files\n",
    "#NB_EPISODES = 300 #2000\n",
    "MODE = 'train' # train or test mode\n",
    "#FROM_PRETRAINED = False\n",
    "DATA_DIR = f'../data/{MARKET_NAME}/preprocessed_data/'\n",
    "\n",
    "# Tune and double-check these before every test:\n",
    "USE_FORECASTS = model_parameters[MODEL_BASE_NAME]['use_forecasts'] # whether to use forecasts as inputs to agent policy net or not\n",
    "NB_FORECASTS = model_parameters[MODEL_BASE_NAME]['nb_forecasts'] # number of forecasts to use in state. Set to None for no forecasts\n",
    "FORECAST_TYPE = model_parameters[MODEL_BASE_NAME]['forecast_type'] # use 'strong' or 'weak' forecasts (if no forecasts given, this does not matter)\n",
    "USE_CNN_STATE = model_parameters[MODEL_BASE_NAME]['use_cnn_state'] # whether to pass log-rets block for CNN part of policy net (set to false for forecast only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'maybe_make_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'maybe_make_dir' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "##########################\n",
    "### main training loop ###\n",
    "##########################\n",
    "\n",
    "# define investor preferences to train for\n",
    "#------ extended-boyd-sweep ------#\n",
    "#GAMMA_TRADES = [5.5, 6, 6.5, 7, 7.5, 8, 9, 10, 11, 12, 15, 20, 30]\n",
    "#GAMMA_TRADES = [4, 5]\n",
    "#GAMMA_TRADES = [0.1, 0.5, 1, 2, 3, 45, 60, 100, 200]\n",
    "#GAMMA_RISKS = [0.1, 0.178, 0.316, 0.562, 1, 2, 3, 6, 10, 18, 32, 56, 100, 178, 316, 562, 1000, 2000, 5000, 10000, 20000]\n",
    "#---------------------------------#\n",
    "counter = 0\n",
    "\n",
    "for RANDOM_SEED in SEED_LIST:\n",
    "    model_name = f'{MODEL_BASE_NAME}_seed_{RANDOM_SEED}'\n",
    "    maybe_make_dir(f'../experiments/{MARKET_NAME}/seeded/{MODEL_BASE_NAME}/seed_{RANDOM_SEED}')\n",
    "    \n",
    "    for (GAMMA_TRADE, GAMMA_RISK, GAMMA_HOLD) in GAMMA_TRIOS:\n",
    "        # set random generator seed for tf and np\n",
    "        # this is probably unnecessary because it is done when env is initialised but just incase\n",
    "        tf.random.set_seed(RANDOM_SEED)\n",
    "        np.random.seed(RANDOM_SEED)\n",
    "        counter += 1\n",
    "\n",
    "        # check if test lready done. skip if so\n",
    "        #if not FROM_PRETRAINED:\n",
    "            #skip = os.path.exists(f'experiments/12_assets/00_seeded/seed_{RANDOM_SEED}/trade_{GAMMA_TRADE}_risk_{GAMMA_RISK}') # check if already exists\n",
    "        #else:\n",
    "        \n",
    "        skip = os.path.exists(f'../experiments/{MARKET_NAME}/seeded/{MODEL_BASE_NAME}/seed_{RANDOM_SEED}/trade_{GAMMA_TRADE}_risk_{GAMMA_RISK}_hold_{GAMMA_HOLD}')\n",
    "\n",
    "        if not skip: # if not exists, do test\n",
    "\n",
    "            print('#############################################################################')\n",
    "            print(f'##\\t[{counter}/{len(GAMMA_TRIOS)}]\\tmodel={MODEL_BASE_NAME},\\tSEED={RANDOM_SEED},\\ttrade={GAMMA_TRADE},\\trisk={GAMMA_RISK}\\thold={GAMMA_HOLD}\\t##')\n",
    "            print('#############################################################################')        \n",
    "\n",
    "            # create agent and environment\n",
    "            env = MultiStockEnv(tickers=TICKERS, \n",
    "                                from_date=FROM,\n",
    "                                until=UNTIL, \n",
    "                                #nb_episodes=100,\n",
    "                                cash_key='USDOLLAR', \n",
    "                                gamma_risk=GAMMA_RISK, \n",
    "                                gamma_trade=GAMMA_TRADE,\n",
    "                                gamma_hold=GAMMA_HOLD,\n",
    "                                half_spread=HALF_SPREAD, \n",
    "                                nonlin_coef=NONLIN_COEFF, \n",
    "                                power=POWER, \n",
    "                                datadir=DATA_DIR, \n",
    "                                state_lookback_window=20, \n",
    "                                distribution=EPISODE_DRAW_DISTRIBUTION,\n",
    "                                days_duration=DAYS_IN_EPISODE, \n",
    "                                mode='train', \n",
    "                                random_seed=RANDOM_SEED,\n",
    "                                init_portfolio=INIT_PORTFOLIO, \n",
    "                                period_in_file_name=FILE_PERIOD, \n",
    "                                nb_forecasts=NB_FORECASTS, \n",
    "                                forecast_type=FORECAST_TYPE,\n",
    "                                use_CNN_state=USE_CNN_STATE,\n",
    "                                verbose=False)\n",
    "\n",
    "            agent = Agent(alpha=0.001, \n",
    "                          gamma=0.99, \n",
    "                          n_assets=len(TICKERS)+1, \n",
    "                          tau=5, \n",
    "                          lookback_window=20, \n",
    "                          n_feature_maps=len(TICKERS)+1,\n",
    "                          use_forecasts=USE_FORECASTS,\n",
    "                          use_CNN_state=USE_CNN_STATE,\n",
    "                          allow_long_short_trades=True)\n",
    "\n",
    "            # initialise policy by one forward pass then load pretrained weights\n",
    "            #if FROM_PRETRAINED: \n",
    "                #agent.choose_action(env._get_obs())\n",
    "                #agent.load(pretrined_weights_dir)\n",
    "\n",
    "            # configure folders\n",
    "            experiments_folder = f'../experiments/{MARKET_NAME}'\n",
    "            from_seeded_folder = f'{experiments_folder}/seeded'\n",
    "            base_model_folder = f'{from_seeded_folder}/{MODEL_BASE_NAME}'\n",
    "            seed_folder = f'{base_model_folder}/seed_{RANDOM_SEED}'\n",
    "            #if FROM_PRETRAINED:\n",
    "            #    pretrained_folder = f'{nb_assets_folder}/0_further_trained'\n",
    "            #    preference_folder = f'{pretrained_folder}/trade_{GAMMA_TRADE}_risk_{GAMMA_RISK}'\n",
    "            #else:\n",
    "            preference_folder = f'{seed_folder}/trade_{GAMMA_TRADE}_risk_{GAMMA_RISK}_hold_{GAMMA_HOLD}'\n",
    "            models_folder = f'{preference_folder}/models' # where saved models will be saved\n",
    "            losses_folder = f'{preference_folder}/losses' # where losses will be saved for plotting training progress\n",
    "            fig_folder = f'{preference_folder}/figures'\n",
    "\n",
    "            # create dirictories for saving outputs to (if they don't exist already)\n",
    "            #maybe_make_dir(nb_assets_folder)\n",
    "            maybe_make_dir(seed_folder)\n",
    "            maybe_make_dir(preference_folder)\n",
    "            maybe_make_dir(models_folder)\n",
    "            maybe_make_dir(losses_folder)\n",
    "            maybe_make_dir(fig_folder)\n",
    "\n",
    "            if MODE == 'train':\n",
    "                # play the game num_episodes times and update weights according to loss\n",
    "                losses = []\n",
    "                for e in range(NB_EPISODES):\n",
    "\n",
    "                    # save model weights every few episodes\n",
    "                    if (e%SAVE_EVERY == 0) and (e!=0):\n",
    "                        agent.save(f'{models_folder}/{model_name}_{e}')\n",
    "                        # save losses of training period\n",
    "                        np.save(f'{losses_folder}/{model_name}_{MODE}_{e}_losses.npy', np.array(losses))\n",
    "\n",
    "                    t0 = datetime.datetime.now()\n",
    "                    try:\n",
    "                        loss = play_one_episode(agent, env, MODE)\n",
    "                    except Exception as err:\n",
    "                        print(f'\\t*** error in episode {e}:', err)\n",
    "                        loss = np.nan#5.0 # just an arbitraty number that seems high compared to usual losses\n",
    "                    dt = datetime.datetime.now() - t0\n",
    "                    losses.append(loss) # append episode loss\n",
    "                    # print progress\n",
    "                    if (e%10 == 0):\n",
    "                        print(f\"episode: {e + 1}/{NB_EPISODES}, loss: {loss:.4f}, duration: {dt}\")\n",
    "\n",
    "\n",
    "                # save the weights and losses when done\t\n",
    "                agent.save(f'{models_folder}/{model_name}_{NB_EPISODES}')\n",
    "                np.save(f'{losses_folder}/{model_name}_{MODE}_{NB_EPISODES}_losses.npy', np.array(losses))\n",
    "\n",
    "            # plot losses\n",
    "            save_fig = True\n",
    "\n",
    "            # load losses file\n",
    "            file = f'{losses_folder}/{model_name}_{MODE}_{NB_EPISODES}_losses.npy'\n",
    "            loaded_losses = np.load(file)\n",
    "\n",
    "            # plot losses\n",
    "            plt.figure(figsize=(14,5))\n",
    "            plt.plot(loaded_losses)\n",
    "            plt.title(f'{model_name} Training Loss')\n",
    "            plt.xlabel('Episode Number')\n",
    "            plt.ylabel(r'Loss: $-G \\approx -\\mathbb{E}\\left[ \\sum_{k=0}^{T} \\gamma^k R_t \\right]$')\n",
    "            #plt.yscale('symlog')\n",
    "            if save_fig:\n",
    "                plt.savefig(f'{fig_folder}/{model_name}_losses.png', dpi=150, facecolor=None, edgecolor=None, bbox_inches='tight')\n",
    "            plt.clf()\n",
    "\n",
    "        else:\n",
    "            print(f'\\talready exists: trade_{GAMMA_TRADE}_risk_{GAMMA_RISK}_hold_{GAMMA_HOLD}')\n",
    "            print('\\tskip to next.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check the end of training\n",
    "#env.until"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training done.\n"
     ]
    }
   ],
   "source": [
    "print('training done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now repeat this for the different RL models.\n",
    "### remember to update the gamma-pairs, model base name, and model specs/setup in beginning of notebook!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
